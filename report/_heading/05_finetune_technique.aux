\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Fine-Tuning Techniques for Large Language Models}{47}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Overview of Fine-Tuning}{47}{section.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces From pre-trained LLM to final model ready for deployment through fine-tuning.}}{48}{figure.caption.20}\protected@file@percent }
\newlabel{fig:finetune_overview_2}{{5.1}{48}{From pre-trained LLM to final model ready for deployment through fine-tuning}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Supervised fine-tuning of a base LLM using specific (possibly private) knowledge.}}{49}{figure.caption.21}\protected@file@percent }
\newlabel{fig:finetune_overview_1}{{5.2}{49}{Supervised fine-tuning of a base LLM using specific (possibly private) knowledge}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Types of Fine-Tuning Techniques}{49}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Full Fine-Tuning}{49}{subsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Illustration of the full fine-tuning process, showing how all parameters of a pre-trained LLM are updated using a domain-specific dataset to create a fine-tuned model that can handle specialized queries.}}{50}{figure.caption.22}\protected@file@percent }
\newlabel{fig:full-fine-tuning}{{5.3}{50}{Illustration of the full fine-tuning process, showing how all parameters of a pre-trained LLM are updated using a domain-specific dataset to create a fine-tuned model that can handle specialized queries}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Adapter-Based Fine-Tuning}{51}{subsection.5.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Architectural diagram of adapter-based fine-tuning showing the integration of bottleneck adapter modules within a pre-trained language model. The left panel illustrates adapter placement within the transformer architecture, while the right panel details the internal structure of a bottleneck adapter module.}}{51}{figure.caption.23}\protected@file@percent }
\newlabel{fig:adapter-fine-tuning}{{5.4}{51}{Architectural diagram of adapter-based fine-tuning showing the integration of bottleneck adapter modules within a pre-trained language model. The left panel illustrates adapter placement within the transformer architecture, while the right panel details the internal structure of a bottleneck adapter module}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Low-Rank Adaptation (LoRA)}{52}{subsection.5.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Comparison between standard linear projection (left) and Low-Rank Adaptation (right), illustrating how LoRA decomposes weight updates into low-rank matrices A and B that operate in parallel with frozen pre-trained weights.}}{53}{figure.caption.24}\protected@file@percent }
\newlabel{fig:lora-adaptation}{{5.5}{53}{Comparison between standard linear projection (left) and Low-Rank Adaptation (right), illustrating how LoRA decomposes weight updates into low-rank matrices A and B that operate in parallel with frozen pre-trained weights}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Prefix-Tuning}{54}{subsection.5.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Architecture of prefix-tuning. The left side shows the overall Transformer structure with attention and feed-forward blocks repeated L times. The right side illustrates the prefix mechanism, where trainable prefix vectors $P_K$ and $P_V$ are prepended to keys and values in the attention mechanism. The prefix undergoes reparameterization through a small MLP with up-projection, nonlinearity, and down-projection steps before being added to the attention computation.}}{55}{figure.caption.25}\protected@file@percent }
\newlabel{fig:prefix_tuning}{{5.6}{55}{Architecture of prefix-tuning. The left side shows the overall Transformer structure with attention and feed-forward blocks repeated L times. The right side illustrates the prefix mechanism, where trainable prefix vectors $P_K$ and $P_V$ are prepended to keys and values in the attention mechanism. The prefix undergoes reparameterization through a small MLP with up-projection, nonlinearity, and down-projection steps before being added to the attention computation}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Architecture of prompt-tuning for classification tasks. The continuous soft prompts are prepended to tokenized inputs at the embedding layer. Special tokens like [CLS], [MASK], and [SEP] maintain their functionality while the model processes both the soft prompts and regular input through its layers (L1 through L12). The output is then processed by a masked language model (MLM) head and verbalizer to produce the target classification.}}{56}{figure.caption.26}\protected@file@percent }
\newlabel{fig:prompt_tuning}{{5.7}{56}{Architecture of prompt-tuning for classification tasks. The continuous soft prompts are prepended to tokenized inputs at the embedding layer. Special tokens like [CLS], [MASK], and [SEP] maintain their functionality while the model processes both the soft prompts and regular input through its layers (L1 through L12). The output is then processed by a masked language model (MLM) head and verbalizer to produce the target classification}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Prompt-Tuning}{56}{subsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.6}Instruction Tuning}{57}{subsection.5.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces The two-stage process of instruction tuning. Step 1 (left) illustrates the instruction dataset construction, where text-label templates and seed instructions are expanded using stronger models like ChatGPT and GPT-4 to generate diverse instruction-output pairs. Step 2 (right) shows the actual instruction tuning phase, where the constructed dataset is used to perform supervised fine-tuning on the target LLM.}}{58}{figure.caption.27}\protected@file@percent }
\newlabel{fig:instruction_tuning}{{5.8}{58}{The two-stage process of instruction tuning. Step 1 (left) illustrates the instruction dataset construction, where text-label templates and seed instructions are expanded using stronger models like ChatGPT and GPT-4 to generate diverse instruction-output pairs. Step 2 (right) shows the actual instruction tuning phase, where the constructed dataset is used to perform supervised fine-tuning on the target LLM}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Complete RLHF training pipeline. The process begins with pretraining on large text corpora (left), followed by supervised fine-tuning on demonstration data. The RLHF-specific components (outlined by the dashed box) include reward model training from human comparison data and reinforcement learning optimization. The figure also shows typical data scales for each stage and examples of models that have used these techniques.}}{59}{figure.caption.28}\protected@file@percent }
\newlabel{fig:rlhf_pipeline}{{5.9}{59}{Complete RLHF training pipeline. The process begins with pretraining on large text corpora (left), followed by supervised fine-tuning on demonstration data. The RLHF-specific components (outlined by the dashed box) include reward model training from human comparison data and reinforcement learning optimization. The figure also shows typical data scales for each stage and examples of models that have used these techniques}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.7}Reinforcement Learning from Human Feedback (RLHF)}{59}{subsection.5.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Advantages and Disadvantages of Fine-Tuning Methods}{61}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Full Fine-Tuning}{61}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.1}Advantages}{61}{subsubsection.5.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.2}Disadvantages}{61}{subsubsection.5.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.3}Practical Considerations}{61}{subsubsection.5.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Adapter-Based Fine-Tuning}{62}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2.1}Advantages}{62}{subsubsection.5.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2.2}Disadvantages}{62}{subsubsection.5.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2.3}Practical Considerations}{62}{subsubsection.5.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Low-Rank Adaptation (LoRA)}{63}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3.1}Advantages}{63}{subsubsection.5.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3.2}Disadvantages}{63}{subsubsection.5.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3.3}Practical Considerations}{64}{subsubsection.5.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Prefix-Tuning}{64}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.1}Advantages}{64}{subsubsection.5.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.2}Disadvantages}{64}{subsubsection.5.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.3}Practical Considerations}{65}{subsubsection.5.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Prompt-Tuning}{65}{subsection.5.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.1}Advantages}{65}{subsubsection.5.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.2}Disadvantages}{66}{subsubsection.5.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.3}Practical Considerations}{66}{subsubsection.5.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Instruction Tuning}{66}{subsection.5.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6.1}Advantages}{66}{subsubsection.5.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6.2}Disadvantages}{67}{subsubsection.5.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6.3}Practical Considerations}{67}{subsubsection.5.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.7}Reinforcement Learning from Human Feedback (RLHF)}{67}{subsection.5.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.7.1}Advantages}{67}{subsubsection.5.3.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.7.2}Disadvantages}{68}{subsubsection.5.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.7.3}Practical Considerations}{68}{subsubsection.5.3.7.3}\protected@file@percent }
\@setckpt{_heading/05_finetune_technique}{
\setcounter{page}{69}
\setcounter{equation}{4}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{3}
\setcounter{subsection}{7}
\setcounter{subsubsection}{3}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{9}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{section@level}{0}
\setcounter{Item}{14}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{theorem}{0}
\setcounter{property}{0}
\setcounter{proposition}{0}
\setcounter{definition}{0}
\setcounter{lstnumber}{1}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{float@type}{32}
\setcounter{algorithm}{0}
\setcounter{lastpagecount}{0}
\setcounter{csvinputline}{0}
\setcounter{csvrow}{0}
\setcounter{csvcol}{0}
\setcounter{FancyVerbLine}{0}
\setcounter{subsubsubsection}{0}
\setcounter{tcbbreakpart}{0}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{0}
\setcounter{tcbrastercolumn}{1}
\setcounter{tcbrasterrow}{1}
\setcounter{tcbrasternum}{1}
\setcounter{tcbraster}{0}
\setcounter{tcblisting}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{0}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{cbx@tempcnta}{0}
\setcounter{cbx@tempcntb}{0}
\setcounter{cbx@tempcntc}{0}
\setcounter{cbx@tempcntd}{0}
\setcounter{lstlisting}{0}
}
